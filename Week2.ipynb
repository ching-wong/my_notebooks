{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ching-wong/my_notebooks/blob/main/Week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Models, Layers, and Loss Functions with TensorFlow - Week 2\n",
        "\n",
        "How to define custom loss functions."
      ],
      "metadata": {
        "id": "VqW8A7V0q51z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Custom Models, Layers, and Loss Functions with TensorFlow - Week 2](#scrollTo=VqW8A7V0q51z)\n",
        "\n",
        ">>[Using loss functions](#scrollTo=GpV1fDf9gXlP)\n",
        "\n",
        ">>[Define and use custom loss function](#scrollTo=kwgv-zCaQatF)\n",
        "\n",
        ">>[Loss function as a class](#scrollTo=UTyJ0YJnUMfM)\n",
        "\n",
        ">>[Example: Contrastive loss](#scrollTo=E8ntZsuUZnT3)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "blo5iFwQe974"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using loss functions\n",
        "\n",
        "We usually specify which loss function we want to use in the compile function.\n",
        "\n",
        "For example, we have a simple model with only one dense layer."
      ],
      "metadata": {
        "id": "GpV1fDf9gXlP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MPsoxkDDK67E"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "input = Input(shape=[1])\n",
        "predictions = Dense(1, activation=\"softmax\", name=\"dense\")(input)\n",
        "\n",
        "simple_model = Model(inputs = input, outputs = predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# option 1: use a string\n",
        "simple_model.compile(loss='mse', optimizer='sgd')\n",
        "\n",
        "# option 2: import the class, which allows us to change the hyperparameters\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "simple_model.compile(loss=MeanSquaredError(reduction = \"sum\"), optimizer='sgd')"
      ],
      "metadata": {
        "id": "iZTwIr1hO-ao"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define and use custom loss function\n",
        "\n",
        "A loss function should take two inputs: y_true and y_pred."
      ],
      "metadata": {
        "id": "kwgv-zCaQatF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss_function(y_true, y_pred):\n",
        "\n",
        "  return abs(y_true-y_pred)"
      ],
      "metadata": {
        "id": "iuwnhIE0QksC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compile, simply use the function we just defined."
      ],
      "metadata": {
        "id": "e73otEqwSilT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model.compile(loss=custom_loss_function, optimizer='sgd')"
      ],
      "metadata": {
        "id": "o7eMHzWoSfyh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One can also set other parameters for the custom loss function by using a wrapper. In this example, we have para as a hyperparameter for the custom loss function."
      ],
      "metadata": {
        "id": "VaxdUBVUTbqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss_function_with_parameters(para = 3):\n",
        "\n",
        "  def loss_function(y_true, y_pred):\n",
        "\n",
        "    return abs(y_true-y_pred)*para\n",
        "\n",
        "  return loss_function"
      ],
      "metadata": {
        "id": "VTWnkKfxTCx9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compile, we use the outer function with the parameters we want."
      ],
      "metadata": {
        "id": "WQ_D3Qr_To-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model.compile(loss=custom_loss_function_with_parameters(para = 5), optimizer='sgd')"
      ],
      "metadata": {
        "id": "SKBMWDlMTrvg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function as a class\n",
        "\n",
        "Loss functions can be implemented as classes. It should be inherited from the Loss class."
      ],
      "metadata": {
        "id": "UTyJ0YJnUMfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import Loss\n",
        "\n",
        "class MyLossClass(Loss):\n",
        "\n",
        "  def __init__(self, para):\n",
        "    super().__init__()\n",
        "    self.para = para\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "    return abs(y_true-y_pred)*self.para"
      ],
      "metadata": {
        "id": "0-DGcHTpVgRQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then compile the model as usual."
      ],
      "metadata": {
        "id": "MYaYIa_uYFYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model.compile(loss=MyLossClass(para = 5), optimizer='sgd')"
      ],
      "metadata": {
        "id": "chd4tY8qYNwF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Contrastive loss\n",
        "\n",
        "In the Siamese network, we use the contrastive loss.\n",
        "\n",
        "The essence is: Two images are similar, if and only if they produce similar feature vector.\n",
        "\n",
        "The formula is:\n",
        "$$\\text{loss} = Y * D^2 + (1-Y) * \\max(\\text{margin} - D, 0)^2,$$\n",
        "\n",
        "where\n",
        "\n",
        "* $Y$ is the tensor, 1 if the images are similar, 0 if not,\n",
        "* $D$ is the tensor, Euclidean distances between pair of images,\n",
        "* margin is a constant, distance threshold to determine similar or not.\n",
        "\n",
        "When $Y = 1$, $\\text{loss} = D^2$.\n",
        "\n",
        "When $Y = 0$, $\\text{loss} = \\max(\\text{margin} - D, 0)^2$.\n",
        "\n",
        "$Y$ should be the y_true and $D$ should be y_pred.\n",
        "\n",
        "Note: K.square(x) is element-wise squaring in TensorFlow tensors.\n"
      ],
      "metadata": {
        "id": "E8ntZsuUZnT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def contrastive_loss_with_margin(margin):\n",
        "    def contrastive_loss(y_true, y_pred):\n",
        "        square_pred = K.square(y_pred)\n",
        "        margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "        return (y_true * square_pred + (1 - y_true) * margin_square)\n",
        "    return contrastive_loss"
      ],
      "metadata": {
        "id": "uCrqRhbjchyg"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}